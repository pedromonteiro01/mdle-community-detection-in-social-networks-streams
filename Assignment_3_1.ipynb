{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDLE - Community Detection in Social Networks Streams\n",
    "### Exercise 1\n",
    "##### Authors: Pedro Duarte 97673, Pedro Monteiro 97484"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.clustering import PowerIterationClustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as pltcolors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sorted eigendecomposition of the Laplacian matrix of a graph.\n",
    "\n",
    "Parameters:\n",
    "- G: NetworkX graph object\n",
    "    Graph according to the eigendecomposition\n",
    "- k: int\n",
    "    Number of eigenvalues and eigenvectors\n",
    "\n",
    "Returns:\n",
    "- eigenvalues: numpy array\n",
    "    Eigenvalues sorted in ascending order\n",
    "- eigenvectors: numpy array\n",
    "    Eigenvectors sorted based on eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_eigendecomposition(G, k):\n",
    "\n",
    "  # compute Laplacian matrix, eigenvalues and eigenvectors\n",
    "  laplacian_matrix = nx.normalized_laplacian_matrix(G).toarray()\n",
    "  eigenvalues, eigenvectors = scipy.sparse.linalg.eigs(laplacian_matrix, k)\n",
    "\n",
    "  # check if the eigenvalues or eigenvectors have complex values\n",
    "  if np.iscomplexobj(eigenvalues) or np.iscomplexobj(eigenvectors):\n",
    "    # convert to real values\n",
    "    eigenvalues = np.real(eigenvalues)\n",
    "    eigenvectors = np.real(eigenvectors)\n",
    "  \n",
    "  # sort eigenvalues and eigenvectors in ascending order\n",
    "  sorted_indices = np.argsort(eigenvalues)\n",
    "  eigenvalues = eigenvalues[sorted_indices]\n",
    "  eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "  return eigenvalues, eigenvectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the ideal number of clusters based on the eigenvalues of a graph Laplacian.\n",
    "\n",
    "Parameters:\n",
    "- eigenvalues: numpy array\n",
    "    Eigenvalues sorted in ascending order\n",
    "\n",
    "Returns:\n",
    "- n_clusters: int\n",
    "    Ideal number of clusters based on the eigenvalue spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ideal_clusters_n(eigenvalues):\n",
    "  eigengap = np.diff(eigenvalues) # difference between consecutive eigenvalues\n",
    "\n",
    "  eigengap_peaks = np.where(np.diff(eigengap) < 0)[0] # indices where the difference between consecutive eigengap values becomes negative\n",
    "  return eigengap_peaks[0] + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview a clustering result by drawing nodes with different colors based on their cluster labels\n",
    "\n",
    "Parameters:\n",
    "- G: NetworkX graph object\n",
    "    Graph to be visualized\n",
    "- pos: dictionary\n",
    "    Node positions\n",
    "- cluster_labels: list\n",
    "    List of cluster labels for each node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_clustering(G, pos, cluster_labels):\n",
    "  # Draw the nodes with different colors based on their cluster labels\n",
    "  next_color = [.6, .4, .3]\n",
    "  for cluster_label in range(20):\n",
    "      # generate a new color for each cluster label\n",
    "      next_color[(cluster_label*5)%3] = (next_color[(cluster_label)%3] + .28*cluster_label) % 1\n",
    "      # get current cluster label nodes\n",
    "      nodes_in_cluster = [node for node, label in zip(G.nodes(), cluster_labels) if label == cluster_label]\n",
    "      nx.draw_networkx_nodes(G, pos, nodelist=nodes_in_cluster, node_color=pltcolors.to_hex(next_color), node_size=10)\n",
    "\n",
    "  plt.title('Spectral Clustering')\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform K-means clustering on a subset of eigenvectors to partition the data into clusters\n",
    "\n",
    "Parameters:\n",
    "- eigenvectors: numpy array\n",
    "    Eigenvectors sorted based on eigenvalues\n",
    "- n_clusters: int\n",
    "    Desired number of clusters\n",
    "\n",
    "Returns:\n",
    "- cluster_labels: numpy array\n",
    "    Cluster labels assigned to each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster_partitioning(eigenvectors, n_clusters):\n",
    "  cluster_vectors = eigenvectors[:, :n_clusters] # get a subset of eigenvectors for clustering\n",
    "\n",
    "  kmeans = KMeans(n_clusters=n_clusters)\n",
    "  return kmeans.fit_predict(cluster_vectors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform spectral clustering on a graph using the scikit-learn library\n",
    "\n",
    "Parameters:\n",
    "- G: NetworkX graph object\n",
    "    Graph to be clustered\n",
    "- n_clusters: int\n",
    "    Desired number of clusters.\n",
    "\n",
    "Returns:\n",
    "- cluster_labels: numpy array\n",
    "    Cluster labels assigned to each node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scikit_cluster_partitioning(G, n_clusters):\n",
    "  spectral_clustering = SpectralClustering(n_clusters, eigen_solver='amg', affinity='precomputed', n_jobs=4)\n",
    "  return spectral_clustering.fit_predict(nx.adjacency_matrix(G, weight=None).toarray())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cluster partitioning using Spark MLlib's PowerIterationClustering algorithm\n",
    "\n",
    "Parameters:\n",
    "- G: NetworkX graph object\n",
    "    Graph to be partitioned\n",
    "- n_clusters: int\n",
    "    Desired number of clusters\n",
    "\n",
    "Returns:\n",
    "- cluster_labels: list\n",
    "    Cluster labels assigned to each node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_cluster_partitioning(G, n_clusters):\n",
    "  # spark constants\n",
    "  APP_NAME = 'assignment1'\n",
    "  MASTER = 'local[*]'\n",
    "\n",
    "  # create the SparkSession and SparkContext\n",
    "  spark = SparkSession.builder.appName(\"SpectralClustering\").getOrCreate()\n",
    "  conf = SparkConf().setAppName(APP_NAME).setMaster(MASTER)\n",
    "  sc = SparkContext.getOrCreate(conf=conf)\n",
    "  \n",
    "  # convert graph edges to the required format for PowerIterationClustering\n",
    "  edges = [(int(edge[0]), int(edge[1]), 1.0) for edge in G.edges()]\n",
    "  rdd = sc.parallelize(edges)\n",
    "  \n",
    "  model = PowerIterationClustering.train(rdd, n_clusters, 10, 'degree') # train the PowerIterationClustering model\n",
    "  cluster_labels = model.assignments().map(lambda x: x.cluster).collect()\n",
    "\n",
    "  spark.stop()\n",
    "\n",
    "  return cluster_labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Energy Physics - Phenomenology collaboration network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sorted eigendecomposition of the Laplacian matrix for the Phenomenology Collaboration Network and determine the desired number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"ca-HepPh.txt.gz\") # read graph\n",
    "\n",
    "pos = nx.random_layout(G) # generate random node positions\n",
    "\n",
    "optimal_num_clusters = 20\n",
    "# compute the sorted eigendecomposition of the graph Laplacian\n",
    "eigenvalues, eigenvectors = get_sorted_eigendecomposition(G, optimal_num_clusters)\n",
    "\n",
    "optimal_num_clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform K-means clustering on a subset of eigenvectors obtained from the eigendecomposition of a graph's Laplacian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = kmeans_cluster_partitioning(eigenvectors, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels) # preview the result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform spectral clustering on a graph using the scikit-learn library's SpectralClustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = scikit_cluster_partitioning(G, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cluster partitioning on a graph using Spark MLlib's PowerIterationClustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = spark_cluster_partitioning(G, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social circles: Facebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sorted eigendecomposition of the Laplacian matrix for the Facebook Network and determine the desired number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist(\"facebook_combined.txt.gz\")\n",
    "\n",
    "pos = nx.random_layout(G)\n",
    "\n",
    "optimal_num_clusters = 20\n",
    "eigenvalues, eigenvectors = get_sorted_eigendecomposition(G, optimal_num_clusters)\n",
    "\n",
    "optimal_num_clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform K-means clustering on a subset of eigenvectors obtained from the eigendecomposition of a graph's Laplacian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = kmeans_cluster_partitioning(eigenvectors, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform spectral clustering on a graph using the scikit-learn library's SpectralClustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = scikit_cluster_partitioning(G, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cluster partitioning on a graph using Spark MLlib's PowerIterationClustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = spark_cluster_partitioning(G, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human protein-protein interaction network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sorted eigendecomposition of the Laplacian matrix for the Human protein-protein interaction network and determine the desired number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"PP-Pathways_ppi.csv.gz\", header=None)\n",
    "\n",
    "G = nx.from_pandas_edgelist(data, source=0, target=1)\n",
    "\n",
    "pos = nx.random_layout(G)\n",
    "\n",
    "optimal_num_clusters = 20\n",
    "eigenvalues, eigenvectors = get_sorted_eigendecomposition(G, optimal_num_clusters)\n",
    "\n",
    "optimal_num_clusters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform K-means clustering on a subset of eigenvectors obtained from the eigendecomposition of a graph's Laplacian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = kmeans_cluster_partitioning(eigenvectors, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform spectral clustering on a graph using the scikit-learn library's SpectralClustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = scikit_cluster_partitioning(G, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cluster partitioning on a graph using Spark MLlib's PowerIterationClustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = spark_cluster_partitioning(G, optimal_num_clusters)\n",
    "preview_clustering(G, pos, cluster_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
